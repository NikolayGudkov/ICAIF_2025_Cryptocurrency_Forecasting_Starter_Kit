{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757c4d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "224242e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths (adjust if your layout differs)\n",
    "ROOT = Path('/home/pduce/ICAIF_2025_Cryptocurrency_Forecasting_Starter_Kit')\n",
    "DATA = ROOT / \"data\"\n",
    "SRC  = ROOT / \"src\"\n",
    "SUBM = ROOT / \"sample_submission\"\n",
    "\n",
    "# Ensure src is importable\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "# Create sample_submission dir if missing\n",
    "SUBM.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24746d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_info.json loaded. Keys: ['freq', 'features', 'input_len', 'horizon_len', 'dtypes', 'outputs', 'sha256']\n",
      "{\n",
      "  \"features\": [\n",
      "    \"close\",\n",
      "    \"volume\"\n",
      "  ],\n",
      "  \"input_len\": 60,\n",
      "  \"horizon_len\": 10,\n",
      "  \"outputs\": {\n",
      "    \"train\": {\n",
      "      \"columns\": [\n",
      "        \"series_id\",\n",
      "        \"time_step\",\n",
      "        \"close\",\n",
      "        \"volume\"\n",
      "      ]\n",
      "    },\n",
      "    \"x_test\": {\n",
      "      \"columns\": [\n",
      "        \"window_id\",\n",
      "        \"time_step\",\n",
      "        \"close\",\n",
      "        \"volume\"\n",
      "      ]\n",
      "    },\n",
      "    \"y_test_local\": {\n",
      "      \"columns\": [\n",
      "        \"window_id\",\n",
      "        \"time_step\",\n",
      "        \"close\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "train shape: (18331224, 5) | columns: ['series_id', 'time_step', 'close', 'volume', 'event_time']\n",
      "x_test  shape: (3000000, 4) | columns: ['window_id', 'time_step', 'close', 'volume']\n",
      "y_test_local shape: (20, 3) | columns: ['window_id', 'time_step', 'close']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>event_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13700</td>\n",
       "      <td>171985.703125</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>85451.398438</td>\n",
       "      <td>2024-01-01 00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.13647</td>\n",
       "      <td>121151.898438</td>\n",
       "      <td>2024-01-01 00:02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  time_step    close         volume          event_time\n",
       "0          1          0  0.13700  171985.703125 2024-01-01 00:00:00\n",
       "1          1          1  0.13656   85451.398438 2024-01-01 00:01:00\n",
       "2          1          2  0.13647  121151.898438 2024-01-01 00:02:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>24976.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>2299.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_id  time_step   close   volume\n",
       "0          1          0  0.1126  24976.0\n",
       "1          1          1  0.1126      0.0\n",
       "2          1          2  0.1125   2299.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_id  time_step   close\n",
       "0          1          0  0.1131\n",
       "1          1          1  0.1131\n",
       "2          1          2  0.1130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset files\n",
    "info_path = DATA / \"dataset_info.json\"\n",
    "if info_path.exists():\n",
    "    info = json.loads(info_path.read_text(encoding=\"utf-8\"))\n",
    "    print(\"dataset_info.json loaded. Keys:\", list(info.keys()))\n",
    "    print(json.dumps({k: info[k] for k in ['features','input_len','horizon_len','outputs']}, indent=2))\n",
    "else:\n",
    "    print(\"dataset_info.json not found at\", info_path)\n",
    "\n",
    "# Peek train / x_test\n",
    "train_path = DATA / \"train.pkl\"\n",
    "x_test_path  = DATA / \"x_test.pkl\"\n",
    "y_local_path = DATA / \"y_test_local.pkl\"\n",
    "\n",
    "train = pd.read_pickle(train_path)\n",
    "train['event_time'] = pd.to_datetime('2024-01-01') + train['time_step']*pd.Timedelta(minutes=1) \n",
    "x_test  = pd.read_pickle(x_test_path)\n",
    "y_test_local = pd.read_pickle(y_local_path)\n",
    "\n",
    "print(\"train shape:\", train.shape, \"| columns:\", train.columns.tolist())\n",
    "print(\"x_test  shape:\", x_test.shape,  \"| columns:\", x_test.columns.tolist())\n",
    "print(\"y_test_local shape:\", y_test_local.shape, \"| columns:\", y_test_local.columns.tolist())\n",
    "\n",
    "display(train.head(3))\n",
    "display(x_test.head(3))\n",
    "display(y_test_local.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e388b33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-27 11:14:48.575368: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-27 11:14:51.101651: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "from keras_sig import jax_gpu_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fc07482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW / UPDATED CODE\n",
    "\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List, Optional, Iterable, Callable, Tuple\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# --- your existing imports ---\n",
    "from icaif.dataset import TrainWindowSampler, TrainWindowSamplerVect\n",
    "from athenea.stats.regressions import Ridge\n",
    "from icaif.metrics import evaluate_all_metrics\n",
    "\n",
    "SEED = 42  # ensure you define this somewhere\n",
    "\n",
    "class WindowsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wrap TrainWindowSampler into a PyTorch Dataset.\n",
    "    Returns:\n",
    "      X: (60, 2) float32 -> [close, volume]\n",
    "      y: (10,)  float32 -> future close\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, train_path: str = None, rolling: bool = True, step_size: int = 1, max_samples: int = None):\n",
    "        self.sampler = TrainWindowSampler(\n",
    "            df=df,\n",
    "            train_path=train_path,\n",
    "            window=70,\n",
    "            input_len=60,\n",
    "            horizon_len=10,\n",
    "            rolling=rolling,\n",
    "            step_size=step_size,\n",
    "            seed=SEED,\n",
    "        )\n",
    "        # Materialize (optionally capped) for stable batching\n",
    "        xs, ys = [], []\n",
    "        for i, (X, y) in enumerate(self.sampler.iter_windows()):\n",
    "            xs.append(X.astype(np.float32))\n",
    "            ys.append(y.astype(np.float32))\n",
    "            if max_samples is not None and (i + 1) >= max_samples:\n",
    "                break\n",
    "        self.X = np.stack(xs, axis=0) if xs else np.zeros((0,60,2), dtype=np.float32)\n",
    "        self.y = np.stack(ys, axis=0) if ys else np.zeros((0,10), dtype=np.float32)\n",
    "\n",
    "    def __len__(self):  return len(self.X)\n",
    "    def __getitem__(self, i):\n",
    "        return torch.from_numpy(self.X[i]), torch.from_numpy(self.y[i])\n",
    "\n",
    "class WindowsDatasetVect(Dataset):\n",
    "    \"\"\"\n",
    "    Vectorized implementation of the WindowsDataset.\n",
    "\n",
    "    Returns:\n",
    "      X: (60, 2) float32 -> [close, volume]\n",
    "      y: (10,)  float32 -> future close\n",
    "      time_X: (60,) datetime64[ns] -> event timestamps for X window\n",
    "      time_y: (10,) datetime64[ns] -> event timestamps for y window\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, train_path: str = None, rolling: bool = True, step_size: int = 1, max_samples: int = None):\n",
    "        self.sampler = TrainWindowSamplerVect(\n",
    "            df=df,\n",
    "            train_path=train_path,\n",
    "            window=70,\n",
    "            input_len=60,\n",
    "            horizon_len=10,\n",
    "            rolling=rolling,\n",
    "            step_size=step_size,\n",
    "            seed=SEED,\n",
    "        )\n",
    "\n",
    "        all_X_groups = []\n",
    "        all_y_groups = []\n",
    "        all_timeX_groups = []\n",
    "        all_timey_groups = []\n",
    "\n",
    "        for sid, group_df in self.sampler.groups.items():\n",
    "            n = len(group_df)\n",
    "            if n < self.sampler.window:\n",
    "                continue\n",
    "\n",
    "            # --- values array (close, volume) ---\n",
    "            arr = group_df[['close', 'volume']].to_numpy(dtype=np.float32)\n",
    "\n",
    "            # --- event_time as UTC nanoseconds (int64) for safe vectorization ---\n",
    "            # works for tz-aware or naive inputs\n",
    "            event_ns = pd.to_datetime(group_df['event_time'], utc=True).view('int64').to_numpy()\n",
    "\n",
    "            num_windows = (n - self.sampler.window) // self.sampler.step_size + 1\n",
    "            if num_windows <= 0:\n",
    "                continue\n",
    "\n",
    "            window_len = self.sampler.window\n",
    "            step = self.sampler.step_size\n",
    "\n",
    "            # windows for values (shape: num_windows x 70 x 2)\n",
    "            strides_vals = (step * arr.strides[0], arr.strides[0], arr.strides[1])\n",
    "            shape_vals = (num_windows, window_len, 2)\n",
    "            all_windows_view = np.lib.stride_tricks.as_strided(arr, shape=shape_vals, strides=strides_vals)\n",
    "\n",
    "            # windows for times (shape: num_windows x 70)\n",
    "            strides_time = (step * event_ns.strides[0], event_ns.strides[0])\n",
    "            shape_time = (num_windows, window_len)\n",
    "            time_windows_view_ns = np.lib.stride_tricks.as_strided(event_ns, shape=shape_time, strides=strides_time)\n",
    "\n",
    "            # split into X / y\n",
    "            X_group_view = all_windows_view[:, :self.sampler.input_len, :]\n",
    "            y_group_view = all_windows_view[:, self.sampler.input_len:, 0]\n",
    "\n",
    "            timeX_group_view_ns = time_windows_view_ns[:, :self.sampler.input_len]\n",
    "            timey_group_view_ns = time_windows_view_ns[:, self.sampler.input_len:]\n",
    "\n",
    "            # materialize copies and cast times back to datetime64[ns]\n",
    "            all_X_groups.append(X_group_view.copy())\n",
    "            all_y_groups.append(y_group_view.copy())\n",
    "\n",
    "            all_timeX_groups.append(timeX_group_view_ns.copy().view('datetime64[ns]'))\n",
    "            all_timey_groups.append(timey_group_view_ns.copy().view('datetime64[ns]'))\n",
    "\n",
    "        # concat\n",
    "        if all_X_groups:\n",
    "            self.X = np.concatenate(all_X_groups, axis=0)\n",
    "            self.y = np.concatenate(all_y_groups, axis=0)\n",
    "            self.time_X = np.concatenate(all_timeX_groups, axis=0)\n",
    "            self.time_y = np.concatenate(all_timey_groups, axis=0)\n",
    "\n",
    "            if max_samples is not None:\n",
    "                self.X = self.X[:max_samples]\n",
    "                self.y = self.y[:max_samples]\n",
    "                self.time_X = self.time_X[:max_samples]\n",
    "                self.time_y = self.time_y[:max_samples]\n",
    "        else:\n",
    "            self.X = np.zeros((0, self.sampler.input_len, 2), dtype=np.float32)\n",
    "            self.y = np.zeros((0, self.sampler.horizon_len), dtype=np.float32)\n",
    "            self.time_X = np.empty((0, self.sampler.input_len), dtype='datetime64[ns]')\n",
    "            self.time_y = np.empty((0, self.sampler.horizon_len), dtype='datetime64[ns]')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # Keep dataloader tensors unchanged; times stay on the object\n",
    "        return torch.from_numpy(self.X[i]), torch.from_numpy(self.y[i])\n",
    "\n",
    "\n",
    "\n",
    "def transform(X):\n",
    "    \"\"\"\n",
    "    X: array-like of shape (n_samples, 60, 2)\n",
    "       [:, :, 0] = prices (close); [:, :, 1] = volumes\n",
    "    Returns: list[pd.DataFrame], each of shape (n_samples, 1)\n",
    "    \"\"\"\n",
    "    EPS = 1e-12\n",
    "\n",
    "    # Arrange as (time x samples)\n",
    "    X_prices  = pd.DataFrame(X[:, :, 0]).T\n",
    "    X_volumes = pd.DataFrame(X[:, :, 1]).T\n",
    "\n",
    "    logp    = np.log(X_prices)\n",
    "    logrets = logp.diff()  # 1-min log returns, time on rows\n",
    "\n",
    "    # ----- Your original features (named) -----\n",
    "    avg_lr        = logrets.mean().to_frame()\n",
    "    sign_change_share = np.sign(logrets).diff().ne(0).sum().to_frame()\n",
    "    avg_vol_lr = logrets.mul(X_volumes,axis=0).mean().to_frame()\n",
    "    vd = np.sign(logrets).mul(X_volumes,axis=0).mean().to_frame()\n",
    "    rv = logrets.pow(2).mean().to_frame()\n",
    "\n",
    "\n",
    "    features = [\n",
    "        avg_lr,\n",
    "        avg_vol_lr,\n",
    "        vd,\n",
    "        rv,\n",
    "    ]\n",
    "\n",
    "    #sig = jax_gpu_signature(X, depth=3)\n",
    "    #df_sig = pd.DataFrame(sig)\n",
    "    #print(df_sig.head())\n",
    "    return features\n",
    "\n",
    "from features_compute import build_features_np\n",
    "def transform_nick(X):\n",
    "    return [pd.DataFrame(f) for f in build_features_np(X)]\n",
    "\n",
    "def evaluate(y_pred, X, y_true, time_y):\n",
    "    df_prices = pd.DataFrame(X[:, :, 0]).T\n",
    "    y_pred[0] = 0\n",
    "    y_pred = y_pred.cumsum(axis=1)\n",
    "    y_pred = y_pred.mul(df_prices.iloc[-1],axis=0)\n",
    "    submission_df = y_pred.stack().reset_index().rename(columns={0:'pred_close','level_0':'window_id','level_1':'time_step'})\n",
    "\n",
    "    df_x = pd.DataFrame(\n",
    "    {\n",
    "        \"window_id\": np.repeat(np.arange(X.shape[0]), X.shape[1]),\n",
    "        \"time_step\": np.tile(np.arange(X.shape[1]), X.shape[0]),\n",
    "        \"close\": X[:,:,0].flatten(),\n",
    "        \"volume\": X[:,:,1].flatten()\n",
    "    })\n",
    "\n",
    "    df_y = pd.DataFrame(\n",
    "        {\n",
    "            \"window_id\": np.repeat(np.arange(y_true.shape[0]), y_true.shape[1]),\n",
    "            \"time_step\": np.tile(np.arange(y_true.shape[1]), y_true.shape[0]),\n",
    "            \"close\": y_true.flatten(),\n",
    "            \"event_datetime\": time_y.flatten()\n",
    "        }\n",
    "    )\n",
    "\n",
    "    y_true_val = df_y[[\"window_id\", \"time_step\",\"close\", \"event_datetime\"]].copy()\n",
    "    x_val = (\n",
    "        df_x[df_x[\"time_step\"] == 59]\n",
    "        [[\"window_id\", \"time_step\", \"close\"]]\n",
    "        .copy()\n",
    "    )\n",
    "    \n",
    "    results = evaluate_all_metrics(\n",
    "        y_true=y_true_val,\n",
    "        y_pred=submission_df,\n",
    "        x_test=x_val,\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "# --------------- NEW: worker function ---------------\n",
    "def _run_one_fold(\n",
    "    idx: int,\n",
    "    train_ids: np.ndarray,\n",
    "    val_ids: np.ndarray,\n",
    "    df_train: pd.DataFrame,\n",
    "    model_or_factory: Any,\n",
    ") -> Tuple[int, str, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Execute a single fold end-to-end and return (idx, fold_name, metrics).\n",
    "    Runs in a separate process when parallelized.\n",
    "    \"\"\"\n",
    "    # Rebuild model per process\n",
    "    model = model_or_factory() if callable(model_or_factory) else copy.deepcopy(model_or_factory)\n",
    "\n",
    "    # Slice data for this fold\n",
    "    df_tr = df_train[df_train['series_id'].isin(train_ids)].copy()\n",
    "    df_va = df_train[df_train['series_id'].isin(val_ids)].copy()\n",
    "\n",
    "    # Defensive: skip degenerate folds\n",
    "    if df_tr.empty or df_va.empty:\n",
    "        return idx, f\"val_{'-'.join(map(str, val_ids))}\", {}\n",
    "\n",
    "    # Build datasets\n",
    "    train_ds = WindowsDatasetVect(df_tr, rolling=True, step_size=1)\n",
    "    val_ds   = WindowsDatasetVect(df_va, rolling=True, step_size=1)\n",
    "\n",
    "    # Your original training target construction\n",
    "    df_y_train = np.log(pd.DataFrame(train_ds.y)).diff(axis=1)\n",
    "\n",
    "    # Fit / predict / evaluate\n",
    "    train_features = model.transform(train_ds.X)\n",
    "    val_features = model.transform(val_ds.X)\n",
    "\n",
    "    preds = []\n",
    "    for i in range(1,10):\n",
    "        model.fit(df_y_train[i].to_frame(0),train_features, )\n",
    "        y_pred = model.predict(val_features).rename(columns={0:i})\n",
    "        preds.append(y_pred)\n",
    "\n",
    "    y_pred = pd.concat(preds, axis=1)\n",
    "\n",
    "    metrics: Dict[str, Any] = model.evaluate(y_pred, val_ds.X, val_ds.y, val_ds.time_y)\n",
    "\n",
    "    fold_name = f\"val_{'-'.join(map(str, val_ids))}\"\n",
    "    return idx, fold_name, metrics\n",
    "\n",
    "\n",
    "# --------------- UPDATED: run_cv with parallelism ---------------\n",
    "def run_cv(\n",
    "    df_train: pd.DataFrame,\n",
    "    n_train: int = 4,\n",
    "    n_val: int = 1,\n",
    "    model=None,\n",
    "    *,\n",
    "    include_last_fold: bool = False,   # set True to include the final possible window\n",
    "    n_jobs: int = 1,                   # NEW: #processes; 1 keeps it sequential\n",
    "    model_factory: Optional[Callable[[], Any]] = None,  # NEW: pass to rebuild model per fold\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rolling group-based CV, optionally parallel across folds (process-based).\n",
    "    Assumptions about `model` / `model_factory`:\n",
    "      - Either:\n",
    "          model_factory() -> fresh model with fit/predict/evaluate/transform\n",
    "        Or:\n",
    "          model is a picklable object with those methods (we deep-copy it per fold).\n",
    "    \"\"\"\n",
    "    if (model is None) and (model_factory is None):\n",
    "        raise ValueError(\"Provide either `model` or a `model_factory` (callable returning a fresh model).\")\n",
    "\n",
    "    series_ids = df_train['series_id'].unique()\n",
    "    n_series   = len(series_ids)\n",
    "    n_total    = n_train + n_val\n",
    "\n",
    "    if n_total > n_series:\n",
    "        raise ValueError(f\"n_train + n_val must be ≤ number of groups ({n_series}).\")\n",
    "    if n_train < 1:\n",
    "        raise ValueError(f\"n_train must be ≥ 1 (got {n_train}).\")\n",
    "    if n_val < 1:\n",
    "        raise ValueError(f\"n_val must be ≥ 1 (got {n_val}).\")\n",
    "    if n_train < n_val:\n",
    "        raise ValueError(f\"n_train must be ≥ n_val (got {n_train} < {n_val}).\")\n",
    "\n",
    "    start = n_total\n",
    "    stop  = n_series + (1 if include_last_fold else 0)\n",
    "\n",
    "    # Build fold definitions once\n",
    "    fold_specs = []\n",
    "    for i in range(start, stop):\n",
    "        train_ids = series_ids[i - n_total : i - n_val]\n",
    "        val_ids   = series_ids[i - n_val   : i]\n",
    "        fold_specs.append((i, train_ids, val_ids))\n",
    "\n",
    "    if not fold_specs:\n",
    "        raise RuntimeError(\"No folds were produced. Check your data and parameters.\")\n",
    "\n",
    "    # Choose what to pass to workers for model creation\n",
    "    model_or_factory = model_factory if model_factory is not None else model\n",
    "\n",
    "    # Sequential path (n_jobs == 1)\n",
    "    if n_jobs == 1:\n",
    "        results = [\n",
    "            _run_one_fold(idx, train_ids, val_ids, df_train, model_or_factory)\n",
    "            for (idx, train_ids, val_ids) in fold_specs\n",
    "        ]\n",
    "    else:\n",
    "        # Parallel path (processes)\n",
    "        # Tip: to avoid CPU over-subscription with BLAS, consider setting env vars:\n",
    "        # OMP_NUM_THREADS=1 MKL_NUM_THREADS=1 NUMEXPR_NUM_THREADS=1\n",
    "        results = [None] * len(fold_specs)\n",
    "        with ProcessPoolExecutor(max_workers=n_jobs) as ex:\n",
    "            futures = {\n",
    "                ex.submit(_run_one_fold, idx, train_ids, val_ids, df_train, model_or_factory): pos\n",
    "                for pos, (idx, train_ids, val_ids) in enumerate(fold_specs)\n",
    "            }\n",
    "            for fut in as_completed(futures):\n",
    "                pos = futures[fut]\n",
    "                results[pos] = fut.result()\n",
    "\n",
    "    # results: list of (idx, fold_name, metrics)\n",
    "    # Keep chronological order by fold index\n",
    "    results.sort(key=lambda t: t[0])\n",
    "    fold_names = [name for _, name, _ in results]\n",
    "    metric_rows = [metrics for _, _, metrics in results]\n",
    "\n",
    "    # Assemble DataFrame: rows = metric names, cols = folds\n",
    "    metrics_df = pd.DataFrame(metric_rows, index=fold_names).T\n",
    "    return metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef53c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from athenea.stats.regressions import Ridge\n",
    "def make_ridge(l2=0.1):\n",
    "    model = Ridge(l2=l2)\n",
    "    model.transform = transform_nick\n",
    "    model.evaluate = evaluate\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7f7eca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_60439/3548666775.py:87: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  event_ns = pd.to_datetime(group_df['event_time'], utc=True).view('int64').to_numpy()\n",
      "/tmp/ipykernel_60439/3548666775.py:87: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  event_ns = pd.to_datetime(group_df['event_time'], utc=True).view('int64').to_numpy()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "metrics = run_cv(\n",
    "    df_train=train[train['series_id']<=2],\n",
    "    n_train=1,\n",
    "    n_val=1,\n",
    "    include_last_fold=True,\n",
    "    n_jobs=1,                 # ← parallel across 8 processes\n",
    "    model_factory=make_ridge(l2=1), # ← safe across processes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8a90aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.306488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.533383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IR</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SharpeRatio</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDD</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VaR</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                val_2\n",
       "MSE          0.306488\n",
       "MAE          0.533383\n",
       "IC           0.000000\n",
       "IR           0.000000\n",
       "SharpeRatio  0.000000\n",
       "MDD          0.000000\n",
       "VaR          0.000000\n",
       "ES           0.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04bc2d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.306488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.533383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IC</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IR</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SharpeRatio</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MDD</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VaR</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ES</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                val_2\n",
       "MSE          0.306488\n",
       "MAE          0.533383\n",
       "IC           0.000000\n",
       "IR           0.000000\n",
       "SharpeRatio  0.000000\n",
       "MDD          0.000000\n",
       "VaR          0.000000\n",
       "ES           0.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "934f6903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0              1             2            3            4   \\\n",
      "0 -0.00143  -99103.968750  1.022435e-06  1136.216064  -994.498352   \n",
      "1 -0.00094   28114.046875  4.417954e-07  1072.388184 -1098.815308   \n",
      "2 -0.00129   56385.750000  8.320607e-07  1004.861084 -1077.599243   \n",
      "3 -0.00176  -16793.250000  1.548811e-06   912.215576  -882.659302   \n",
      "4 -0.00181 -232696.343750  1.638049e-06  1269.294556  -848.114197   \n",
      "\n",
      "             5             6         7         8            9         10  \\\n",
      "0  4.910777e+09 -4.873573e-10 -1.679209  1.733641 -542296640.0 -0.155759   \n",
      "1  3.952394e+08 -1.384283e-10 -1.167127  1.326214 -497052896.0 -0.146667   \n",
      "2  1.589812e+09 -3.577887e-10 -1.033422  0.770564 -430420672.0  0.309774   \n",
      "3  1.410806e+08 -9.086391e-10 -1.409842  1.214179 -378141312.0  0.169654   \n",
      "4  2.707372e+10 -9.882888e-10 -1.942987  1.588552 -580836096.0 -0.026733   \n",
      "\n",
      "             11           12            13  \n",
      "0  9.719899e+08 -436715488.0 -1.618831e+14  \n",
      "1  1.024255e+09 -527573632.0  3.724743e+12  \n",
      "2  9.175012e+08 -489131296.0  2.991037e+13  \n",
      "3  7.409635e+08 -363070368.0 -8.231573e+11  \n",
      "4  8.663120e+08 -334479456.0 -2.099779e+15  \n"
     ]
    }
   ],
   "source": [
    "model = make_ridge()\n",
    "train_ds = WindowsDatasetVect(train, rolling=True, step_size=1)\n",
    "train_features = model.transform(train_ds.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4020789e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0              1             2             3            4   \\\n",
      "0  0.00050   73841.000000  1.250005e-07     22.550888    14.369687   \n",
      "1 -0.00096   89725.554688  4.608034e-07     -4.543301   -81.593529   \n",
      "2  0.00019 -460473.000000  1.805080e-08  -7080.743164  6993.251465   \n",
      "3  0.01489  450706.750000  1.108563e-04  13484.589844 -6773.553711   \n",
      "4  0.00370   -4099.729980  6.844832e-06    180.764969  -195.933838   \n",
      "\n",
      "             5             6           7          8             9          10  \\\n",
      "0  2.726247e+09  2.083346e-11   -0.000733   0.012742  2.346698e+06  -0.002778   \n",
      "1  4.025340e+09 -1.474576e-10   -0.000956   0.006275 -4.293116e+06   0.036028   \n",
      "2  1.060110e+11  1.143594e-12   -6.427595  11.509821  2.708342e+10  -5.090534   \n",
      "3  1.015686e+11  5.502174e-07  123.076736 -45.367538 -3.529163e+09 -27.745413   \n",
      "4  8.403826e+06  8.441710e-09   -1.853161   4.375144 -2.732600e+06  -2.550046   \n",
      "\n",
      "             11            12            13  \n",
      "0 -3.028219e+06  2.044646e+06  6.710408e+13  \n",
      "1  8.178542e+06 -7.749782e+06  1.203891e+14  \n",
      "2 -5.090634e+10  2.384307e+10 -1.634784e+16  \n",
      "3  1.313589e+10 -8.094391e+09  1.525897e+16  \n",
      "4  4.724112e+06 -1.960419e+06 -1.148386e+10  \n"
     ]
    }
   ],
   "source": [
    "test_features = model.transform(x_test[['close','volume']].values.reshape(50000,60,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9432b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_train = np.log(pd.concat([\n",
    "    pd.Series(train_ds.X[:,-1,0]),\n",
    "    pd.DataFrame(train_ds.y),\n",
    "],axis=1)).diff(axis=1).dropna(how='all',axis=1)\n",
    "\n",
    "preds = []\n",
    "all_models = []\n",
    "for i in range(0,10):\n",
    "    model = make_ridge()\n",
    "    model.fit(df_y_train[i].to_frame(0),train_features)\n",
    "    all_models.append(model)\n",
    "    y_pred = model.predict(test_features).rename(columns={0:i})\n",
    "    preds.append(y_pred)\n",
    "\n",
    "y_pred = pd.concat(preds, axis=1)\n",
    "y_pred_prices = np.exp(y_pred.cumsum(axis=1)).mul(x_test[x_test['time_step']==59]['close'].reset_index(drop=True),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "060fbe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/pduce/ICAIF_2025_Cryptocurrency_Forecasting_Starter_Kit/submissions/ridge/model_weights.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(all_models[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af6ac00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = y_pred_prices.stack().reset_index().rename(columns={'level_0':'window_id','level_1':'time_step',0:'pred_close'})\n",
    "submission_df['window_id'] += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87da786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/pduce/ICAIF_2025_Cryptocurrency_Forecasting_Starter_Kit/submissions/ridge/submission.pkl', 'wb') as f:\n",
    "    pickle.dump(submission_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "153518fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSE            1.169836e+02\n",
       "MAE            3.896745e+00\n",
       "IC             1.022314e-03\n",
       "IR             1.558027e-01\n",
       "SharpeRatio    1.455284e+07\n",
       "MDD            0.000000e+00\n",
       "VaR            1.455284e-05\n",
       "ES             1.455284e-05\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.median(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
