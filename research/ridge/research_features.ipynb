{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f105b4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys, json, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390a7080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths (adjust if your layout differs)\n",
    "ROOT = Path('/home/pduce/ICAIF_2025_Cryptocurrency_Forecasting_Starter_Kit')\n",
    "DATA = ROOT / \"data\"\n",
    "SRC  = ROOT / \"src\"\n",
    "SUBM = ROOT / \"sample_submission\"\n",
    "\n",
    "# Ensure src is importable\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC))\n",
    "\n",
    "# Create sample_submission dir if missing\n",
    "SUBM.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda6a73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_info.json loaded. Keys: ['freq', 'features', 'input_len', 'horizon_len', 'dtypes', 'outputs', 'sha256']\n",
      "{\n",
      "  \"features\": [\n",
      "    \"close\",\n",
      "    \"volume\"\n",
      "  ],\n",
      "  \"input_len\": 60,\n",
      "  \"horizon_len\": 10,\n",
      "  \"outputs\": {\n",
      "    \"train\": {\n",
      "      \"columns\": [\n",
      "        \"series_id\",\n",
      "        \"time_step\",\n",
      "        \"close\",\n",
      "        \"volume\"\n",
      "      ]\n",
      "    },\n",
      "    \"x_test\": {\n",
      "      \"columns\": [\n",
      "        \"window_id\",\n",
      "        \"time_step\",\n",
      "        \"close\",\n",
      "        \"volume\"\n",
      "      ]\n",
      "    },\n",
      "    \"y_test_local\": {\n",
      "      \"columns\": [\n",
      "        \"window_id\",\n",
      "        \"time_step\",\n",
      "        \"close\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "train shape: (18331224, 5) | columns: ['series_id', 'time_step', 'close', 'volume', 'event_datetime']\n",
      "x_test  shape: (3000000, 4) | columns: ['window_id', 'time_step', 'close', 'volume']\n",
      "y_test_local shape: (20, 3) | columns: ['window_id', 'time_step', 'close']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>event_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.13700</td>\n",
       "      <td>171985.703125</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.13656</td>\n",
       "      <td>85451.398438</td>\n",
       "      <td>2024-01-01 00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.13647</td>\n",
       "      <td>121151.898438</td>\n",
       "      <td>2024-01-01 00:02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  time_step    close         volume      event_datetime\n",
       "0          1          0  0.13700  171985.703125 2024-01-01 00:00:00\n",
       "1          1          1  0.13656   85451.398438 2024-01-01 00:01:00\n",
       "2          1          2  0.13647  121151.898438 2024-01-01 00:02:00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>24976.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1125</td>\n",
       "      <td>2299.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_id  time_step   close   volume\n",
       "0          1          0  0.1126  24976.0\n",
       "1          1          1  0.1126      0.0\n",
       "2          1          2  0.1125   2299.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   window_id  time_step   close\n",
       "0          1          0  0.1131\n",
       "1          1          1  0.1131\n",
       "2          1          2  0.1130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load dataset files\n",
    "info_path = DATA / \"dataset_info.json\"\n",
    "if info_path.exists():\n",
    "    info = json.loads(info_path.read_text(encoding=\"utf-8\"))\n",
    "    print(\"dataset_info.json loaded. Keys:\", list(info.keys()))\n",
    "    print(json.dumps({k: info[k] for k in ['features','input_len','horizon_len','outputs']}, indent=2))\n",
    "else:\n",
    "    print(\"dataset_info.json not found at\", info_path)\n",
    "\n",
    "# Peek train / x_test\n",
    "train_path = DATA / \"train.pkl\"\n",
    "x_test_path  = DATA / \"x_test.pkl\"\n",
    "y_local_path = DATA / \"y_test_local.pkl\"\n",
    "\n",
    "train = pd.read_pickle(train_path)\n",
    "train['event_datetime'] = pd.to_datetime('2024-01-01') + train['time_step']*pd.Timedelta(minutes=1) \n",
    "x_test  = pd.read_pickle(x_test_path)\n",
    "y_test_local = pd.read_pickle(y_local_path)\n",
    "\n",
    "print(\"train shape:\", train.shape, \"| columns:\", train.columns.tolist())\n",
    "print(\"x_test  shape:\", x_test.shape,  \"| columns:\", x_test.columns.tolist())\n",
    "print(\"y_test_local shape:\", y_test_local.shape, \"| columns:\", y_test_local.columns.tolist())\n",
    "\n",
    "display(train.head(3))\n",
    "display(x_test.head(3))\n",
    "display(y_test_local.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4339ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.lib.stride_tricks import sliding_window_view as swv\n",
    "\n",
    "class WindowsDatasetVect:\n",
    "    \"\"\"\n",
    "    Vectorized window builder that returns two DataFrames:\n",
    "\n",
    "    X columns:\n",
    "      - window_id: integer id of each window\n",
    "      - time_step: 0..(input_len-1) within the input segment\n",
    "      - close\n",
    "      - volume\n",
    "      - event_datetime\n",
    "\n",
    "    y columns:\n",
    "      - window_id: same ids as in X\n",
    "      - time_step: 0..(horizon_len-1) within the future horizon\n",
    "      - close: future close\n",
    "      - prev_close: the last input close (index input_len-1, e.g. 59 when input_len=60)\n",
    "      - event_datetime: timestamps of the future horizon\n",
    "\n",
    "    Notes:\n",
    "      * Requires df to have columns:\n",
    "          ['series_id','time_step','close','volume','event_datetime']\n",
    "      * Windows are created per series_id after sorting by time_step.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        df : pd.DataFrame = None,\n",
    "        train_path: str = None,\n",
    "        window: int = 70,\n",
    "        input_len: int = 60,\n",
    "        horizon_len: int = 10,\n",
    "        rolling: bool = True,\n",
    "        step_size: int | None = None,\n",
    "    ) -> None:\n",
    "        assert input_len + horizon_len == window, \"window must equal input_len + horizon_len\"\n",
    "        # default stepping: 1 if rolling, else full non-overlapping windows\n",
    "        if step_size is None:\n",
    "            step_size = 1 if rolling else window\n",
    "\n",
    "        if train_path is not None:\n",
    "            df = pd.read_pickle(train_path)\n",
    "        if df is None:\n",
    "            raise ValueError(\"Provide either df or train_path\")\n",
    "\n",
    "        required = {'series_id','time_step','close','volume','event_datetime'}\n",
    "        if not required.issubset(df.columns):\n",
    "            raise ValueError(f\"df missing required columns {required}, found {list(df.columns)}\")\n",
    "\n",
    "        # group per series, sorted by time_step\n",
    "        groups = {\n",
    "            sid: g.sort_values(['event_datetime', 'time_step']).reset_index(drop=True)\n",
    "            for sid, g in df.groupby('series_id')\n",
    "        }\n",
    "\n",
    "        X_parts: list[pd.DataFrame] = []\n",
    "        Y_parts: list[pd.DataFrame] = []\n",
    "\n",
    "        next_win_id = 0\n",
    "\n",
    "        for _, g in groups.items():\n",
    "            n = len(g)\n",
    "            if n < window:\n",
    "                continue\n",
    "\n",
    "            close  = g['close' ].to_numpy(np.float32)\n",
    "            volume = g['volume'].to_numpy(np.float32)\n",
    "            dt     = g['event_datetime'].to_numpy('datetime64[ns]')\n",
    "\n",
    "            # sliding windows (shape: (n - window + 1, window))\n",
    "            w_close  = swv(close,  window_shape=window)[::step_size]\n",
    "            w_volume = swv(volume, window_shape=window)[::step_size]\n",
    "            w_dt     = swv(dt,     window_shape=window)[::step_size]\n",
    "\n",
    "            num_win = w_close.shape[0]\n",
    "            if num_win == 0:\n",
    "                continue\n",
    "\n",
    "            # split into input and horizon\n",
    "            x_close  = w_close[:,  :input_len]                      # (num_win, input_len)\n",
    "            x_volume = w_volume[:, :input_len]\n",
    "            x_dt     = w_dt[:,     :input_len]\n",
    "\n",
    "            y_close = w_close[:,  input_len:]                       # (num_win, horizon_len)\n",
    "            y_dt    = w_dt[:,     input_len:]\n",
    "            prev_c  = x_close[:, -1]                                # (num_win,)\n",
    "\n",
    "            # window ids for this group\n",
    "            win_ids = np.arange(next_win_id, next_win_id + num_win, dtype=np.int64)\n",
    "\n",
    "            # X dataframe chunk\n",
    "            X_parts.append(pd.DataFrame({\n",
    "                \"window_id\":     np.repeat(win_ids, input_len)+1,\n",
    "                \"time_step\":     np.tile(np.arange(input_len, dtype=np.int32), num_win),\n",
    "                \"close\":         x_close.reshape(-1),\n",
    "                \"volume\":        x_volume.reshape(-1),\n",
    "                \"event_datetime\": x_dt.reshape(-1),\n",
    "            }))\n",
    "\n",
    "            # y dataframe chunk\n",
    "            Y_parts.append(pd.DataFrame({\n",
    "                \"window_id\":     np.repeat(win_ids, horizon_len)+1,\n",
    "                \"time_step\":     np.tile(np.arange(horizon_len, dtype=np.int32), num_win),\n",
    "                \"close\":         y_close.reshape(-1),\n",
    "                \"prev_close\":    np.repeat(prev_c, horizon_len),\n",
    "                \"event_datetime\": y_dt.reshape(-1),\n",
    "            }))\n",
    "\n",
    "            next_win_id += num_win\n",
    "\n",
    "        # Public attributes\n",
    "        if X_parts:\n",
    "            self.X = pd.concat(X_parts, ignore_index=True)\n",
    "        else:\n",
    "            self.X = pd.DataFrame(columns=[\"window_id\",\"time_step\",\"close\",\"volume\",\"event_datetime\"])\n",
    "\n",
    "        if Y_parts:\n",
    "            self.y = pd.concat(Y_parts, ignore_index=True)\n",
    "        else:\n",
    "            self.y = pd.DataFrame(columns=[\"window_id\",\"time_step\",\"close\",\"prev_close\",\"event_datetime\"])\n",
    "\n",
    "        self.num_windows = int(self.X[\"window_id\"].max()) if len(self.X) else 0\n",
    "        self.input_len = input_len\n",
    "        self.horizon_len = horizon_len\n",
    "        self.window = window\n",
    "        self.step_size = step_size\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_windows\n",
    "\n",
    "    def windows(self, window_id: int) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Convenience: return (X_rows, y_rows) for a given window_id.\"\"\"\n",
    "        Xw = self.X[self.X[\"window_id\"] == window_id].sort_values(\"time_step\")\n",
    "        Yw = self.y[self.y[\"window_id\"] == window_id].sort_values(\"time_step\")\n",
    "        return Xw, Yw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eab68233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from typing import Dict, Any, List, Optional, Iterable, Callable, Tuple\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "# --- your existing imports ---\n",
    "from icaif.dataset import TrainWindowSampler, TrainWindowSamplerVect\n",
    "from athenea.stats.regressions import Ridge\n",
    "from icaif.metrics import evaluate_all_metrics\n",
    "\n",
    "SEED = 42  # ensure you define this somewhere\n",
    "\n",
    "def _features_raw(X):\n",
    "    \"\"\"\n",
    "    X: array-like of shape (n_samples, 60, 2)\n",
    "       [:, :, 0] = prices (close); [:, :, 1] = volumes\n",
    "    Returns: list[pd.DataFrame], each of shape (n_samples, 1)\n",
    "    \"\"\"\n",
    "    # Arrange as (time x samples)\n",
    "    X_prices  = pd.DataFrame(X[:, :, 0]).T\n",
    "    X_volumes = pd.DataFrame(X[:, :, 1]).T\n",
    "\n",
    "    logp    = np.log(X_prices)\n",
    "    logrets = logp.diff()  # 1-min log returns, time on rows\n",
    "    vol_lr  = logrets.mul(X_volumes, axis=0)\n",
    "\n",
    "    cs_price     = logrets.fillna(0).cumsum()\n",
    "    # cs_price_vol = vol_lr.fillna(0).cumsum()  # kept if you need in the future\n",
    "\n",
    "    avg_lr            = logrets.mean().to_frame()\n",
    "    sign_change_share = np.sign(logrets).diff().ne(0).sum().to_frame()  # computed but not used below\n",
    "    avg_vol_lr        = vol_lr.mean().to_frame()\n",
    "    vd                = np.sign(logrets).mul(X_volumes, axis=0).mean().to_frame()\n",
    "    rv                = logrets.pow(2).mean().to_frame()\n",
    "\n",
    "    features = [\n",
    "        avg_lr,\n",
    "        avg_vol_lr,\n",
    "        vd,\n",
    "        rv,\n",
    "    ]\n",
    "\n",
    "    for lag in [3, 5, 10, 20, 30, 40, 50, 60]:\n",
    "        r_tau = cs_price.iloc[-lag:].sum().to_frame(0)\n",
    "        features.append(r_tau)\n",
    "\n",
    "    return features\n",
    "\n",
    "# (Optional) keep old name, but make it a thin wrapper if someone still calls transform()\n",
    "def transform(X):\n",
    "    feats_tr, _ = transform_fit(X)   # fit-once wrapper below\n",
    "    return feats_tr\n",
    "\n",
    "# --- NEW: scaler helpers (fit on train, apply to others) ---\n",
    "from typing import List, Tuple\n",
    "\n",
    "Scaler = List[Tuple[float, float]]  # per-feature (mean, std)\n",
    "\n",
    "def _fit_zscore_scaler(features: List[pd.DataFrame]) -> Scaler:\n",
    "    scaler: Scaler = []\n",
    "    for f in features:\n",
    "        # each f is (n_samples x 1)\n",
    "        mu = float(f.mean().iloc[0])\n",
    "        sd = float(f.std().iloc[0]) + 1e-12\n",
    "        scaler.append((mu, sd))\n",
    "    return scaler\n",
    "\n",
    "def _apply_zscore(features: List[pd.DataFrame], scaler: Scaler) -> List[pd.DataFrame]:\n",
    "    out = []\n",
    "    for f, (mu, sd) in zip(features, scaler):\n",
    "        out.append((f - mu) / sd)\n",
    "    return out\n",
    "\n",
    "def transform_fit(X) -> Tuple[List[pd.DataFrame], Scaler]:\n",
    "    \"\"\"Build raw features, fit scaler on them, return zscored features + scaler.\"\"\"\n",
    "    feats = _features_raw(X)\n",
    "    sc = _fit_zscore_scaler(feats)\n",
    "    return _apply_zscore(feats, sc), sc\n",
    "\n",
    "def transform_apply(X, scaler: Scaler) -> List[pd.DataFrame]:\n",
    "    \"\"\"Build raw features and apply an already-fitted scaler.\"\"\"\n",
    "    feats = _features_raw(X)\n",
    "    return _apply_zscore(feats, scaler)\n",
    "\n",
    "from features_compute import build_features_np\n",
    "\n",
    "def transform_nick(X):\n",
    "    return [pd.DataFrame(f) for f in build_features_np(X)]\n",
    "\n",
    "from icaif.metrics_np import evaluate_all_metrics_vectorized\n",
    "\n",
    "def evaluate(model_results, y_true):\n",
    "    \"\"\"\n",
    "    Backward-compatible evaluator for single-predict case.\n",
    "    If you pass a 1D Series/DataFrame of window-level log-returns,\n",
    "    it repeats each log-return across the 10 future steps.\n",
    "    \"\"\"\n",
    "    y_pred = y_true.copy(deep=True).reset_index(drop=True)\n",
    "\n",
    "    # Accept numpy array, Series or single-column DataFrame\n",
    "    if isinstance(model_results, (pd.Series, pd.DataFrame)):\n",
    "        mr = np.asarray(model_results).reshape(-1)\n",
    "    else:\n",
    "        mr = np.asarray(model_results).reshape(-1)\n",
    "\n",
    "    # Repeat each window prediction for 10 steps, cum-sum in log space, exponentiate\n",
    "    repeated = np.repeat(mr[:, None], 10, axis=1)                 # (n_windows, 10)\n",
    "    factors  = np.exp(np.cumsum(repeated, axis=1))                # multiplicative factors\n",
    "    # prev_close must be aligned per-window first step\n",
    "    prev_close = (\n",
    "        y_true.sort_values(['window_id', 'time_step'])\n",
    "              .set_index(['window_id','time_step'])[['prev_close']]\n",
    "              .to_numpy().reshape(-1, 10)[:, 0]\n",
    "    )\n",
    "    pred_close = (factors * prev_close[:, None]).reshape(-1)\n",
    "    y_pred['pred_close'] = pred_close\n",
    "\n",
    "    results = evaluate_all_metrics_vectorized(\n",
    "        y_true=y_true.sort_values(['window_id','time_step']).reset_index(drop=True),\n",
    "        y_pred=y_pred\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# --------------- NEW/UPDATED: worker function ---------------\n",
    "def _run_one_fold(\n",
    "    idx: int,\n",
    "    train_ids: np.ndarray,\n",
    "    val_ids: np.ndarray,\n",
    "    df_train: pd.DataFrame,\n",
    "    model_or_factory: Any,\n",
    "    single_predict: bool = True,\n",
    ") -> Tuple[int, str, Dict[str, Any], Any, Any]:\n",
    "    \"\"\"\n",
    "    Execute a single fold end-to-end and return (idx, fold_name, metrics, model(s), fit_artifacts).\n",
    "    Runs in a separate process when parallelized.\n",
    "\n",
    "    If single_predict=True: one model on mean log-return (existing behavior).\n",
    "    If single_predict=False: train 10 separate models, one per future-step log-return.\n",
    "    \"\"\"\n",
    "    # Rebuild model per process\n",
    "    base_model = model_or_factory() if callable(model_or_factory) else copy.deepcopy(model_or_factory)\n",
    "\n",
    "    # Slice data for this fold\n",
    "    df_tr = df_train[df_train['series_id'].isin(train_ids)].copy()\n",
    "    df_va = df_train[df_train['series_id'].isin(val_ids)].copy()\n",
    "\n",
    "    # Defensive: skip degenerate folds\n",
    "    if df_tr.empty or df_va.empty:\n",
    "        return idx, f\"val_{'-'.join(map(str, val_ids))}\", {}, None, None\n",
    "\n",
    "    train_ds = WindowsDatasetVect(df_tr, step_size=70)\n",
    "    val_ds   = WindowsDatasetVect(df_va, step_size=70)\n",
    "\n",
    "    # Sort to ensure stable window/time ordering\n",
    "    X_train = train_ds.X.sort_values(['window_id','time_step'])\n",
    "    y_train = train_ds.y.sort_values(['window_id','time_step'])\n",
    "    X_val   = val_ds.X.sort_values(['window_id','time_step'])\n",
    "    y_val   = val_ds.y.sort_values(['window_id','time_step'])\n",
    "\n",
    "    # Build tensors/matrices\n",
    "    X_np_train = (\n",
    "        X_train.set_index(['window_id','time_step'])[['close','volume']]\n",
    "               .to_numpy().reshape(-1, 60, 2)\n",
    "    )\n",
    "    X_np_val = (\n",
    "        X_val.set_index(['window_id','time_step'])[['close','volume']]\n",
    "             .to_numpy().reshape(-1, 60, 2)\n",
    "    )\n",
    "\n",
    "    # For train targets\n",
    "    y_np_train_closes = y_train.set_index(['window_id','time_step'])[['close']].to_numpy().reshape(-1, 10)\n",
    "    prev_close_train  = y_train.set_index(['window_id','time_step'])[['prev_close']].to_numpy().reshape(-1, 10)[:, 0]\n",
    "    y_np_train = np.concatenate([prev_close_train[:, None], y_np_train_closes], axis=1)  # (n_windows, 11)\n",
    "\n",
    "    # For evaluation on val we’ll need prev_close per window\n",
    "    prev_close_val = y_val.set_index(['window_id','time_step'])[['prev_close']].to_numpy().reshape(-1, 10)[:, 0]\n",
    "\n",
    "    # Features (fit on train, apply to val)\n",
    "    features_train, scaler = transform_fit(X_np_train)\n",
    "    features_val           = transform_apply(X_np_val, scaler)\n",
    "\n",
    "    fold_name = f\"val_{'-'.join(map(str, val_ids))}\"\n",
    "\n",
    "    if single_predict:\n",
    "        # --- existing behavior: average log-returns across the 10 steps ---\n",
    "        y_lr_train = pd.Series(np.diff(np.log(y_np_train), axis=1).mean(axis=1)).to_frame()\n",
    "\n",
    "        model = base_model\n",
    "        fit_artifacts = model.fit(y_lr_train, features_train)\n",
    "        # Predict per-window mean log-return for validation set\n",
    "        y_lr_pred = model.predict(features_val)  # (n_val_windows, 1-like)\n",
    "\n",
    "        # Compose a 10-step path by repeating each window's predicted mean\n",
    "        y_true_sorted = y_val.reset_index(drop=True)\n",
    "        # Use the helper 'evaluate' which handles single-predict case\n",
    "        metrics = evaluate(y_lr_pred, y_true_sorted)\n",
    "\n",
    "        return idx, fold_name, metrics, model, fit_artifacts\n",
    "\n",
    "    else:\n",
    "        # --- NEW: 10 separate models, one per horizon log-return ---\n",
    "        y_lr_all = np.diff(np.log(y_np_train), axis=1)   # (n_windows, 10)\n",
    "        n_steps = y_lr_all.shape[1]\n",
    "        models_per_step = []\n",
    "        fits_per_step   = []\n",
    "        preds_per_step  = []\n",
    "\n",
    "        # Helper to create a fresh model each step\n",
    "        def _fresh_model():\n",
    "            return model_or_factory() if callable(model_or_factory) else copy.deepcopy(model_or_factory)\n",
    "\n",
    "        for j in range(n_steps):\n",
    "            y_lr_j = pd.Series(y_lr_all[:, j]).to_frame()  # (n_windows, 1)\n",
    "            m_j = _fresh_model()\n",
    "            fit_j = m_j.fit(y_lr_j, features_train)\n",
    "            y_pred_j = m_j.predict(features_val)           # shape (n_val_windows,)\n",
    "\n",
    "            models_per_step.append(m_j)\n",
    "            fits_per_step.append(fit_j)\n",
    "            preds_per_step.append(np.asarray(y_pred_j).reshape(-1))\n",
    "\n",
    "        # Stack predictions into (n_val_windows, 10)\n",
    "        y_lr_pred_steps = np.column_stack(preds_per_step)\n",
    "        # Turn log-returns into predicted closes per step\n",
    "        factors = np.exp(np.cumsum(y_lr_pred_steps, axis=1))          # (n_val_windows, 10)\n",
    "        pred_close_matrix = factors * prev_close_val[:, None]          # (n_val_windows, 10)\n",
    "        pred_close_flat   = pred_close_matrix.reshape(-1)              # match long format\n",
    "\n",
    "        # Build y_pred aligned to y_val (which we already sorted)\n",
    "        y_true_sorted = y_val.reset_index(drop=True).copy()\n",
    "        y_pred_sorted = y_true_sorted.copy()\n",
    "        y_pred_sorted['pred_close'] = pred_close_flat\n",
    "\n",
    "        # Vectorized metrics\n",
    "        metrics = evaluate_all_metrics_vectorized(\n",
    "            y_true=y_true_sorted,\n",
    "            y_pred=y_pred_sorted,\n",
    "        )\n",
    "\n",
    "        return idx, fold_name, metrics, models_per_step, fits_per_step\n",
    "\n",
    "\n",
    "# --------------- UPDATED: run_cv with parallelism + single_predict flag ---------------\n",
    "def run_cv(\n",
    "    df_train: pd.DataFrame,\n",
    "    n_train: int = 4,\n",
    "    model=None,\n",
    "    *,\n",
    "    include_last_fold: bool = False,   # set True to include the final possible window\n",
    "    n_jobs: int = 1,                   # #processes; 1 keeps it sequential\n",
    "    model_factory: Optional[Callable[[], Any]] = None,  # pass to rebuild model per fold\n",
    "    single_predict: bool = True,       # NEW: True = current code; False = 10 models (one per horizon)\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rolling group-based CV, optionally parallel across folds (process-based).\n",
    "\n",
    "    - If single_predict=True: train one model per fold on the mean of per-step log-returns (existing behavior).\n",
    "    - If single_predict=False: train 10 separate models per fold, one for each horizon log-return.\n",
    "\n",
    "    Assumptions about `model` / `model_factory`:\n",
    "      - Either:\n",
    "          model_factory() -> fresh model with fit/predict methods\n",
    "        Or:\n",
    "          model is a picklable object with those methods (we deep-copy it per fold).\n",
    "    \"\"\"\n",
    "    if (model is None) and (model_factory is None):\n",
    "        raise ValueError(\"Provide either `model` or a `model_factory` (callable returning a fresh model).\")\n",
    "\n",
    "    series_ids = df_train['series_id'].unique()\n",
    "    n_series   = len(series_ids)\n",
    "\n",
    "    if n_train < 1:\n",
    "        raise ValueError(f\"n_train must be ≥ 1 (got {n_train}).\")\n",
    "\n",
    "    start = 0\n",
    "    stop  = n_series + (1 if include_last_fold else 0)\n",
    "\n",
    "    # Build fold definitions once\n",
    "    fold_specs = []\n",
    "    for i in range(start, stop):\n",
    "        train_ids = series_ids[i : i + n_train]\n",
    "        # We validate in the remaining series\n",
    "        val_ids   = [srs_id for srs_id in series_ids if srs_id not in train_ids]\n",
    "        fold_specs.append((i, train_ids, val_ids))\n",
    "\n",
    "    if not fold_specs:\n",
    "        raise RuntimeError(\"No folds were produced. Check your data and parameters.\")\n",
    "\n",
    "    # Choose what to pass to workers for model creation\n",
    "    model_or_factory = model_factory if model_factory is not None else model\n",
    "\n",
    "    # Sequential path (n_jobs == 1)\n",
    "    if n_jobs == 1:\n",
    "        results = [\n",
    "            _run_one_fold(idx, train_ids, val_ids, df_train, model_or_factory, single_predict=single_predict)\n",
    "            for (idx, train_ids, val_ids) in fold_specs\n",
    "        ]\n",
    "    else:\n",
    "        # Parallel path (processes)\n",
    "        # Tip: to avoid CPU over-subscription with BLAS, consider setting env vars:\n",
    "        # OMP_NUM_THREADS=1 MKL_NUM_THREADS=1 NUMEXPR_NUM_THREADS=1\n",
    "        results = [None] * len(fold_specs)\n",
    "        with ProcessPoolExecutor(max_workers=n_jobs) as ex:\n",
    "            futures = {\n",
    "                ex.submit(_run_one_fold, idx, train_ids, val_ids, df_train, model_or_factory, single_predict): pos\n",
    "                for pos, (idx, train_ids, val_ids) in enumerate(fold_specs)\n",
    "            }\n",
    "            for fut in as_completed(futures):\n",
    "                pos = futures[fut]\n",
    "                results[pos] = fut.result()\n",
    "\n",
    "    # results: list of (idx, fold_name, metrics, model(s), fit_artifacts)\n",
    "    # Keep chronological order by fold index\n",
    "    results.sort(key=lambda t: t[0])\n",
    "    fold_names   = [name for _, name, _, _, _ in results]\n",
    "    metric_rows  = [metrics for _, _, metrics, _, _ in results]\n",
    "    models       = [mdl for _, _, _, mdl, _ in results]              # may be a model or a list[models]\n",
    "    fit_artifacts = [art for _, _, _, _, art in results]             # may be any / list\n",
    "\n",
    "    # Assemble DataFrame: rows = metric names, cols = folds\n",
    "    metrics_df = pd.DataFrame(metric_rows, index=fold_names).T\n",
    "    return metrics_df, models, fit_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "918e8a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from athenea.stats.regressions import Ridge\n",
    "from icaif.metrics_np import evaluate_all_metrics_vectorized\n",
    "def make_ridge(l2=0.1):\n",
    "    model = Ridge(l2=l2)\n",
    "    model.transform = transform\n",
    "    model.evaluate = evaluate\n",
    "    return model\n",
    "\n",
    "\n",
    "metrics, models, model_results = run_cv(\n",
    "    df_train=train,\n",
    "    n_train=30,\n",
    "    include_last_fold=True,\n",
    "    n_jobs=4,\n",
    "    model_factory=make_ridge(l2=0.1),\n",
    "    single_predict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "12b88320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSE            21.934642\n",
       "MAE             0.593613\n",
       "IC              0.042382\n",
       "IR              0.136839\n",
       "SharpeRatio     0.051665\n",
       "MDD             0.754754\n",
       "VaR            -0.006733\n",
       "ES             -0.011325\n",
       "dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#False\n",
    "metrics.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6af45b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSE            21.927940\n",
       "MAE             0.594394\n",
       "IC              0.050940\n",
       "IR              0.154523\n",
       "SharpeRatio     0.053322\n",
       "MDD             0.762495\n",
       "VaR            -0.006785\n",
       "ES             -0.011387\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#True\n",
    "metrics.median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91ec2ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_ridge(l2=10000)\n",
    "train_ds = WindowsDatasetVect(train, step_size=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "964a85bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_ds.X\n",
    "y_train = train_ds.y\n",
    "\n",
    "\n",
    "X_np_train = X_train.set_index(['window_id','time_step'])[['close','volume']].to_numpy().reshape(-1, 60, 2)\n",
    "y_np_train = y_train.set_index(['window_id','time_step'])[['close']].to_numpy().reshape(-1, 10)\n",
    "\n",
    "y_lr_train = pd.Series(np.diff(np.log(y_np_train),axis=1).mean(axis=1)).to_frame()\n",
    "\n",
    "features = model.transform(X_np_train)\n",
    "\n",
    "model_results = model.fit(y_lr_train, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "134d113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np_test = x_test[['close','volume']].to_numpy().reshape(-1, 60, 2)\n",
    "\n",
    "features_test = model.transform(X_np_test)\n",
    "\n",
    "y_pred = model.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f64142dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = x_test[x_test['time_step']==59].drop(columns=['time_step']).copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6773a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = pd.DataFrame(\n",
    "    {\n",
    "        'window_id': np.repeat(x_test['window_id'].unique(), 10),\n",
    "        'time_step': np.tile(np.arange(10, dtype=np.int32), len(x_test['window_id'].unique())),\n",
    "        'prev_close': np.repeat(x_test[x_test['time_step']==59]['close'], 10).values,\n",
    "        'pred_ret' : np.exp(y_pred.loc[y_pred.index.repeat(10)].groupby(level=0).cumsum()).reset_index(drop=True)[0],\n",
    "    }\n",
    ")\n",
    "\n",
    "y_test_pred['pred_close'] = y_test_pred['pred_ret'] * y_test_pred['prev_close']\n",
    "y_test_pred = y_test_pred[['window_id','time_step','pred_close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5bd6c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/home/pduce/ICAIF_2025_Cryptocurrency_Forecasting_Starter_Kit/research/ridge/submissions/l2_10000_nonoverlapping/submission.pkl', 'wb') as f:\n",
    "    pickle.dump(y_test_pred, f)\n",
    "\n",
    "with open('/home/pduce/ICAIF_2025_Cryptocurrency_Forecasting_Starter_Kit/research/ridge/submissions/l2_10000_nonoverlapping/model_weights.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6afaccd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>pred_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.113092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.113090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>50000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.169876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>50000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.169872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>50000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.169868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.169863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>50000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.169859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        window_id  time_step  pred_close\n",
       "0               1          0    0.113098\n",
       "1               1          1    0.113096\n",
       "2               1          2    0.113094\n",
       "3               1          3    0.113092\n",
       "4               1          4    0.113090\n",
       "...           ...        ...         ...\n",
       "499995      50000          5    0.169876\n",
       "499996      50000          6    0.169872\n",
       "499997      50000          7    0.169868\n",
       "499998      50000          8    0.169863\n",
       "499999      50000          9    0.169859\n",
       "\n",
       "[500000 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de496763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>pred_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.113098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.113098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>50000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.169890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>50000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.169888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>50000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.169886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.169885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>50000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.169883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        window_id  time_step  pred_close\n",
       "0               1          0    0.113100\n",
       "1               1          1    0.113099\n",
       "2               1          2    0.113099\n",
       "3               1          3    0.113098\n",
       "4               1          4    0.113098\n",
       "...           ...        ...         ...\n",
       "499995      50000          5    0.169890\n",
       "499996      50000          6    0.169888\n",
       "499997      50000          7    0.169886\n",
       "499998      50000          8    0.169885\n",
       "499999      50000          9    0.169883\n",
       "\n",
       "[500000 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57a26aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_id</th>\n",
       "      <th>time_step</th>\n",
       "      <th>pred_close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.113099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.113099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.113099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.113099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499995</th>\n",
       "      <td>50000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.169888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499996</th>\n",
       "      <td>50000</td>\n",
       "      <td>6</td>\n",
       "      <td>0.169886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499997</th>\n",
       "      <td>50000</td>\n",
       "      <td>7</td>\n",
       "      <td>0.169885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499998</th>\n",
       "      <td>50000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.169883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499999</th>\n",
       "      <td>50000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.169881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        window_id  time_step  pred_close\n",
       "0               1          0    0.113100\n",
       "1               1          1    0.113099\n",
       "2               1          2    0.113099\n",
       "3               1          3    0.113099\n",
       "4               1          4    0.113099\n",
       "...           ...        ...         ...\n",
       "499995      50000          5    0.169888\n",
       "499996      50000          6    0.169886\n",
       "499997      50000          7    0.169885\n",
       "499998      50000          8    0.169883\n",
       "499999      50000          9    0.169881\n",
       "\n",
       "[500000 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
